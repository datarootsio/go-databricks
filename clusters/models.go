package clusters

// Code generated by Microsoft (R) AutoRest Code Generator.
// Changes may cause incorrect behavior and will be lost if the code is regenerated.

import (
    "encoding/json"
    "github.com/Azure/go-autorest/autorest"
)

// The package's fully qualified name.
const fqdn = "clusters"

        // Availability enumerates the values for availability.
    type Availability string

    const (
                // ONDEMAND ...
        ONDEMAND Availability = "ON_DEMAND"
                // SPOT ...
        SPOT Availability = "SPOT"
                // SPOTWITHFALLBACK ...
        SPOTWITHFALLBACK Availability = "SPOT_WITH_FALLBACK"
            )
    // PossibleAvailabilityValues returns an array of possible values for the Availability const type.
    func PossibleAvailabilityValues() []Availability {
        return []Availability{ONDEMAND,SPOT,SPOTWITHFALLBACK}
    }

        // Code enumerates the values for code.
    type Code string

    const (
                // CLOUDPROVIDERLAUNCHFAILURE ...
        CLOUDPROVIDERLAUNCHFAILURE Code = "CLOUD_PROVIDER_LAUNCH_FAILURE"
                // CLOUDPROVIDERSHUTDOWN ...
        CLOUDPROVIDERSHUTDOWN Code = "CLOUD_PROVIDER_SHUTDOWN"
                // COMMUNICATIONLOST ...
        COMMUNICATIONLOST Code = "COMMUNICATION_LOST"
                // CONTAINERLAUNCHFAILURE ...
        CONTAINERLAUNCHFAILURE Code = "CONTAINER_LAUNCH_FAILURE"
                // DBFSCOMPONENTUNHEALTHY ...
        DBFSCOMPONENTUNHEALTHY Code = "DBFS_COMPONENT_UNHEALTHY"
                // DRIVERUNREACHABLE ...
        DRIVERUNREACHABLE Code = "DRIVER_UNREACHABLE"
                // DRIVERUNRESPONSIVE ...
        DRIVERUNRESPONSIVE Code = "DRIVER_UNRESPONSIVE"
                // INACTIVITY ...
        INACTIVITY Code = "INACTIVITY"
                // INITSCRIPTFAILURE ...
        INITSCRIPTFAILURE Code = "INIT_SCRIPT_FAILURE"
                // INSTANCEPOOLCLUSTERFAILURE ...
        INSTANCEPOOLCLUSTERFAILURE Code = "INSTANCE_POOL_CLUSTER_FAILURE"
                // INSTANCEUNREACHABLE ...
        INSTANCEUNREACHABLE Code = "INSTANCE_UNREACHABLE"
                // INTERNALERROR ...
        INTERNALERROR Code = "INTERNAL_ERROR"
                // INVALIDARGUMENT ...
        INVALIDARGUMENT Code = "INVALID_ARGUMENT"
                // JOBFINISHED ...
        JOBFINISHED Code = "JOB_FINISHED"
                // METASTORECOMPONENTUNHEALTHY ...
        METASTORECOMPONENTUNHEALTHY Code = "METASTORE_COMPONENT_UNHEALTHY"
                // REQUESTREJECTED ...
        REQUESTREJECTED Code = "REQUEST_REJECTED"
                // SPARKERROR ...
        SPARKERROR Code = "SPARK_ERROR"
                // SPARKSTARTUPFAILURE ...
        SPARKSTARTUPFAILURE Code = "SPARK_STARTUP_FAILURE"
                // TRIALEXPIRED ...
        TRIALEXPIRED Code = "TRIAL_EXPIRED"
                // UNEXPECTEDLAUNCHFAILURE ...
        UNEXPECTEDLAUNCHFAILURE Code = "UNEXPECTED_LAUNCH_FAILURE"
                // USERREQUEST ...
        USERREQUEST Code = "USER_REQUEST"
            )
    // PossibleCodeValues returns an array of possible values for the Code const type.
    func PossibleCodeValues() []Code {
        return []Code{CLOUDPROVIDERLAUNCHFAILURE,CLOUDPROVIDERSHUTDOWN,COMMUNICATIONLOST,CONTAINERLAUNCHFAILURE,DBFSCOMPONENTUNHEALTHY,DRIVERUNREACHABLE,DRIVERUNRESPONSIVE,INACTIVITY,INITSCRIPTFAILURE,INSTANCEPOOLCLUSTERFAILURE,INSTANCEUNREACHABLE,INTERNALERROR,INVALIDARGUMENT,JOBFINISHED,METASTORECOMPONENTUNHEALTHY,REQUESTREJECTED,SPARKERROR,SPARKSTARTUPFAILURE,TRIALEXPIRED,UNEXPECTEDLAUNCHFAILURE,USERREQUEST}
    }

        // EbsVolumeType enumerates the values for ebs volume type.
    type EbsVolumeType string

    const (
                // GENERALPURPOSESSD ...
        GENERALPURPOSESSD EbsVolumeType = "GENERAL_PURPOSE_SSD"
                // THROUGHPUTOPTIMIZEDHDD ...
        THROUGHPUTOPTIMIZEDHDD EbsVolumeType = "THROUGHPUT_OPTIMIZED_HDD"
            )
    // PossibleEbsVolumeTypeValues returns an array of possible values for the EbsVolumeType const type.
    func PossibleEbsVolumeTypeValues() []EbsVolumeType {
        return []EbsVolumeType{GENERALPURPOSESSD,THROUGHPUTOPTIMIZEDHDD}
    }

        // ErrorCode enumerates the values for error code.
    type ErrorCode string

    const (
                // ErrorCodeBADREQUEST ...
        ErrorCodeBADREQUEST ErrorCode = "BAD_REQUEST"
                // ErrorCodeCOULDNOTACQUIRELOCK ...
        ErrorCodeCOULDNOTACQUIRELOCK ErrorCode = "COULD_NOT_ACQUIRE_LOCK"
                // ErrorCodeCUSTOMERUNAUTHORIZED ...
        ErrorCodeCUSTOMERUNAUTHORIZED ErrorCode = "CUSTOMER_UNAUTHORIZED"
                // ErrorCodeDIRECTORYNOTEMPTY ...
        ErrorCodeDIRECTORYNOTEMPTY ErrorCode = "DIRECTORY_NOT_EMPTY"
                // ErrorCodeDIRECTORYPROTECTED ...
        ErrorCodeDIRECTORYPROTECTED ErrorCode = "DIRECTORY_PROTECTED"
                // ErrorCodeDRYRUNFAILED ...
        ErrorCodeDRYRUNFAILED ErrorCode = "DRY_RUN_FAILED"
                // ErrorCodeENDPOINTNOTFOUND ...
        ErrorCodeENDPOINTNOTFOUND ErrorCode = "ENDPOINT_NOT_FOUND"
                // ErrorCodeFEATUREDISABLED ...
        ErrorCodeFEATUREDISABLED ErrorCode = "FEATURE_DISABLED"
                // ErrorCodeINTERNALERROR ...
        ErrorCodeINTERNALERROR ErrorCode = "INTERNAL_ERROR"
                // ErrorCodeINVALIDPARAMETERVALUE ...
        ErrorCodeINVALIDPARAMETERVALUE ErrorCode = "INVALID_PARAMETER_VALUE"
                // ErrorCodeINVALIDSTATE ...
        ErrorCodeINVALIDSTATE ErrorCode = "INVALID_STATE"
                // ErrorCodeINVALIDSTATETRANSITION ...
        ErrorCodeINVALIDSTATETRANSITION ErrorCode = "INVALID_STATE_TRANSITION"
                // ErrorCodeIOERROR ...
        ErrorCodeIOERROR ErrorCode = "IO_ERROR"
                // ErrorCodeMALFORMEDREQUEST ...
        ErrorCodeMALFORMEDREQUEST ErrorCode = "MALFORMED_REQUEST"
                // ErrorCodeMAXBLOCKSIZEEXCEEDED ...
        ErrorCodeMAXBLOCKSIZEEXCEEDED ErrorCode = "MAX_BLOCK_SIZE_EXCEEDED"
                // ErrorCodeMAXNOTEBOOKSIZEEXCEEDED ...
        ErrorCodeMAXNOTEBOOKSIZEEXCEEDED ErrorCode = "MAX_NOTEBOOK_SIZE_EXCEEDED"
                // ErrorCodeMAXREADSIZEEXCEEDED ...
        ErrorCodeMAXREADSIZEEXCEEDED ErrorCode = "MAX_READ_SIZE_EXCEEDED"
                // ErrorCodePERMISSIONDENIED ...
        ErrorCodePERMISSIONDENIED ErrorCode = "PERMISSION_DENIED"
                // ErrorCodeQUOTAEXCEEDED ...
        ErrorCodeQUOTAEXCEEDED ErrorCode = "QUOTA_EXCEEDED"
                // ErrorCodeREQUESTLIMITEXCEEDED ...
        ErrorCodeREQUESTLIMITEXCEEDED ErrorCode = "REQUEST_LIMIT_EXCEEDED"
                // ErrorCodeRESOURCEALREADYEXISTS ...
        ErrorCodeRESOURCEALREADYEXISTS ErrorCode = "RESOURCE_ALREADY_EXISTS"
                // ErrorCodeRESOURCEDOESNOTEXIST ...
        ErrorCodeRESOURCEDOESNOTEXIST ErrorCode = "RESOURCE_DOES_NOT_EXIST"
                // ErrorCodeRESOURCELIMITEXCEEDED ...
        ErrorCodeRESOURCELIMITEXCEEDED ErrorCode = "RESOURCE_LIMIT_EXCEEDED"
                // ErrorCodeTEMPORARILYUNAVAILABLE ...
        ErrorCodeTEMPORARILYUNAVAILABLE ErrorCode = "TEMPORARILY_UNAVAILABLE"
            )
    // PossibleErrorCodeValues returns an array of possible values for the ErrorCode const type.
    func PossibleErrorCodeValues() []ErrorCode {
        return []ErrorCode{ErrorCodeBADREQUEST,ErrorCodeCOULDNOTACQUIRELOCK,ErrorCodeCUSTOMERUNAUTHORIZED,ErrorCodeDIRECTORYNOTEMPTY,ErrorCodeDIRECTORYPROTECTED,ErrorCodeDRYRUNFAILED,ErrorCodeENDPOINTNOTFOUND,ErrorCodeFEATUREDISABLED,ErrorCodeINTERNALERROR,ErrorCodeINVALIDPARAMETERVALUE,ErrorCodeINVALIDSTATE,ErrorCodeINVALIDSTATETRANSITION,ErrorCodeIOERROR,ErrorCodeMALFORMEDREQUEST,ErrorCodeMAXBLOCKSIZEEXCEEDED,ErrorCodeMAXNOTEBOOKSIZEEXCEEDED,ErrorCodeMAXREADSIZEEXCEEDED,ErrorCodePERMISSIONDENIED,ErrorCodeQUOTAEXCEEDED,ErrorCodeREQUESTLIMITEXCEEDED,ErrorCodeRESOURCEALREADYEXISTS,ErrorCodeRESOURCEDOESNOTEXIST,ErrorCodeRESOURCELIMITEXCEEDED,ErrorCodeTEMPORARILYUNAVAILABLE}
    }

        // Source enumerates the values for source.
    type Source string

    const (
                // API ...
        API Source = "API"
                // JOB ...
        JOB Source = "JOB"
                // UI ...
        UI Source = "UI"
            )
    // PossibleSourceValues returns an array of possible values for the Source const type.
    func PossibleSourceValues() []Source {
        return []Source{API,JOB,UI}
    }

        // State enumerates the values for state.
    type State string

    const (
                // ERROR ...
        ERROR State = "ERROR"
                // PENDING ...
        PENDING State = "PENDING"
                // RESIZING ...
        RESIZING State = "RESIZING"
                // RESTARTING ...
        RESTARTING State = "RESTARTING"
                // RUNNING ...
        RUNNING State = "RUNNING"
                // TERMINATED ...
        TERMINATED State = "TERMINATED"
                // TERMINATING ...
        TERMINATING State = "TERMINATING"
                // UNKNOWN ...
        UNKNOWN State = "UNKNOWN"
            )
    // PossibleStateValues returns an array of possible values for the State const type.
    func PossibleStateValues() []State {
        return []State{ERROR,PENDING,RESIZING,RESTARTING,RUNNING,TERMINATED,TERMINATING,UNKNOWN}
    }

        // Status enumerates the values for status.
    type Status string

    const (
                // NotAvailableInRegion ...
        NotAvailableInRegion Status = "NotAvailableInRegion"
                // NotEnabledOnSubscription ...
        NotEnabledOnSubscription Status = "NotEnabledOnSubscription"
            )
    // PossibleStatusValues returns an array of possible values for the Status const type.
    func PossibleStatusValues() []Status {
        return []Status{NotAvailableInRegion,NotEnabledOnSubscription}
    }

            // Attributes ...
            type Attributes struct {
            NumWorkers *int32 `json:"num_workers,omitempty"`
            Autoscale *AutoScale `json:"autoscale,omitempty"`
            ClusterName *string `json:"cluster_name,omitempty"`
            SparkVersion *string `json:"spark_version,omitempty"`
            SparkConf map[string]*string `json:"spark_conf"`
            AwsAttributes *AwsAttributes `json:"aws_attributes,omitempty"`
            NodeTypeID *string `json:"node_type_id,omitempty"`
            DriverNodeTypeID *string `json:"driver_node_type_id,omitempty"`
            SSHPublicKeys *[]string `json:"ssh_public_keys,omitempty"`
            CustomTags map[string]*string `json:"custom_tags"`
            ClusterLogConf *LogConf `json:"cluster_log_conf,omitempty"`
            InitScripts *[]InitScriptInfo `json:"init_scripts,omitempty"`
            DockerImage *DockerImage `json:"docker_image,omitempty"`
            SparkEnvVars map[string]*string `json:"spark_env_vars"`
            AutoterminationMinutes *int32 `json:"autotermination_minutes,omitempty"`
            EnableElasticDisk *bool `json:"enable_elastic_disk,omitempty"`
            InstancePoolID *string `json:"instance_pool_id,omitempty"`
            IdempotencyToken *string `json:"idempotency_token,omitempty"`
            }

        // MarshalJSON is the custom marshaler for Attributes.
        func (a Attributes)MarshalJSON() ([]byte, error){
        objectMap := make(map[string]interface{})
                if(a.NumWorkers != nil) {
                objectMap["num_workers"] = a.NumWorkers
                }
                if(a.Autoscale != nil) {
                objectMap["autoscale"] = a.Autoscale
                }
                if(a.ClusterName != nil) {
                objectMap["cluster_name"] = a.ClusterName
                }
                if(a.SparkVersion != nil) {
                objectMap["spark_version"] = a.SparkVersion
                }
                if(a.SparkConf != nil) {
                objectMap["spark_conf"] = a.SparkConf
                }
                if(a.AwsAttributes != nil) {
                objectMap["aws_attributes"] = a.AwsAttributes
                }
                if(a.NodeTypeID != nil) {
                objectMap["node_type_id"] = a.NodeTypeID
                }
                if(a.DriverNodeTypeID != nil) {
                objectMap["driver_node_type_id"] = a.DriverNodeTypeID
                }
                if(a.SSHPublicKeys != nil) {
                objectMap["ssh_public_keys"] = a.SSHPublicKeys
                }
                if(a.CustomTags != nil) {
                objectMap["custom_tags"] = a.CustomTags
                }
                if(a.ClusterLogConf != nil) {
                objectMap["cluster_log_conf"] = a.ClusterLogConf
                }
                if(a.InitScripts != nil) {
                objectMap["init_scripts"] = a.InitScripts
                }
                if(a.DockerImage != nil) {
                objectMap["docker_image"] = a.DockerImage
                }
                if(a.SparkEnvVars != nil) {
                objectMap["spark_env_vars"] = a.SparkEnvVars
                }
                if(a.AutoterminationMinutes != nil) {
                objectMap["autotermination_minutes"] = a.AutoterminationMinutes
                }
                if(a.EnableElasticDisk != nil) {
                objectMap["enable_elastic_disk"] = a.EnableElasticDisk
                }
                if(a.InstancePoolID != nil) {
                objectMap["instance_pool_id"] = a.InstancePoolID
                }
                if(a.IdempotencyToken != nil) {
                objectMap["idempotency_token"] = a.IdempotencyToken
                }
                return json.Marshal(objectMap)
        }

            // AutoScale ...
            type AutoScale struct {
            MinWorkers *int32 `json:"min_workers,omitempty"`
            MaxWorkers *int32 `json:"max_workers,omitempty"`
            }

            // AwsAttributes ...
            type AwsAttributes struct {
            FirstOnDemand *int32 `json:"first_on_demand,omitempty"`
            // Availability - Possible values include: 'SPOT', 'ONDEMAND', 'SPOTWITHFALLBACK'
            Availability Availability `json:"availability,omitempty"`
            ZoneID *string `json:"zone_id,omitempty"`
            InstanceProfileArn *string `json:"instance_profile_arn,omitempty"`
            SpotBidPricePercent *int32 `json:"spot_bid_price_percent,omitempty"`
            // EbsVolumeType - Possible values include: 'GENERALPURPOSESSD', 'THROUGHPUTOPTIMIZEDHDD'
            EbsVolumeType EbsVolumeType `json:"ebs_volume_type,omitempty"`
            EbsVolumeCount *int32 `json:"ebs_volume_count,omitempty"`
            EbsVolumeSize *int32 `json:"ebs_volume_size,omitempty"`
            }

            // CloudProviderNodeInfo ...
            type CloudProviderNodeInfo struct {
            // Status - Possible values include: 'NotEnabledOnSubscription', 'NotAvailableInRegion'
            Status Status `json:"status,omitempty"`
            AvailableCoreQuota *int32 `json:"available_core_quota,omitempty"`
            TotalCoreQuota *int32 `json:"total_core_quota,omitempty"`
            }

            // CreateResult ...
            type CreateResult struct {
            autorest.Response `json:"-"`
            ClusterID *string `json:"cluster_id,omitempty"`
            }

            // DbfsStorageInfo ...
            type DbfsStorageInfo struct {
            Destination *string `json:"destination,omitempty"`
            }

            // DeleteAttributes ...
            type DeleteAttributes struct {
            ClusterID *string `json:"cluster_id,omitempty"`
            }

            // DockerBasicAuth ...
            type DockerBasicAuth struct {
            Username *string `json:"username,omitempty"`
            Password *string `json:"password,omitempty"`
            }

            // DockerImage ...
            type DockerImage struct {
            URL *string `json:"url,omitempty"`
            BasicAuth *DockerBasicAuth `json:"basic_auth,omitempty"`
            }

            // EditAttributes ...
            type EditAttributes struct {
            NumWorkers *int32 `json:"num_workers,omitempty"`
            Autoscale *AutoScale `json:"autoscale,omitempty"`
            ClusterID *string `json:"cluster_id,omitempty"`
            ClusterName *string `json:"cluster_name,omitempty"`
            SparkVersion *string `json:"spark_version,omitempty"`
            SparkConf map[string]*string `json:"spark_conf"`
            AwsAttributes *AwsAttributes `json:"aws_attributes,omitempty"`
            NodeTypeID *string `json:"node_type_id,omitempty"`
            DriverNodeTypeID *string `json:"driver_node_type_id,omitempty"`
            SSHPublicKeys *[]string `json:"ssh_public_keys,omitempty"`
            CustomTags map[string]*string `json:"custom_tags"`
            ClusterLogConf *LogConf `json:"cluster_log_conf,omitempty"`
            InitScripts *[]InitScriptInfo `json:"init_scripts,omitempty"`
            DockerImage *DockerImage `json:"docker_image,omitempty"`
            SparkEnvVars map[string]*string `json:"spark_env_vars"`
            AutoterminationMinutes *int32 `json:"autotermination_minutes,omitempty"`
            EnableElasticDisk *bool `json:"enable_elastic_disk,omitempty"`
            InstancePoolID *string `json:"instance_pool_id,omitempty"`
            }

        // MarshalJSON is the custom marshaler for EditAttributes.
        func (ea EditAttributes)MarshalJSON() ([]byte, error){
        objectMap := make(map[string]interface{})
                if(ea.NumWorkers != nil) {
                objectMap["num_workers"] = ea.NumWorkers
                }
                if(ea.Autoscale != nil) {
                objectMap["autoscale"] = ea.Autoscale
                }
                if(ea.ClusterID != nil) {
                objectMap["cluster_id"] = ea.ClusterID
                }
                if(ea.ClusterName != nil) {
                objectMap["cluster_name"] = ea.ClusterName
                }
                if(ea.SparkVersion != nil) {
                objectMap["spark_version"] = ea.SparkVersion
                }
                if(ea.SparkConf != nil) {
                objectMap["spark_conf"] = ea.SparkConf
                }
                if(ea.AwsAttributes != nil) {
                objectMap["aws_attributes"] = ea.AwsAttributes
                }
                if(ea.NodeTypeID != nil) {
                objectMap["node_type_id"] = ea.NodeTypeID
                }
                if(ea.DriverNodeTypeID != nil) {
                objectMap["driver_node_type_id"] = ea.DriverNodeTypeID
                }
                if(ea.SSHPublicKeys != nil) {
                objectMap["ssh_public_keys"] = ea.SSHPublicKeys
                }
                if(ea.CustomTags != nil) {
                objectMap["custom_tags"] = ea.CustomTags
                }
                if(ea.ClusterLogConf != nil) {
                objectMap["cluster_log_conf"] = ea.ClusterLogConf
                }
                if(ea.InitScripts != nil) {
                objectMap["init_scripts"] = ea.InitScripts
                }
                if(ea.DockerImage != nil) {
                objectMap["docker_image"] = ea.DockerImage
                }
                if(ea.SparkEnvVars != nil) {
                objectMap["spark_env_vars"] = ea.SparkEnvVars
                }
                if(ea.AutoterminationMinutes != nil) {
                objectMap["autotermination_minutes"] = ea.AutoterminationMinutes
                }
                if(ea.EnableElasticDisk != nil) {
                objectMap["enable_elastic_disk"] = ea.EnableElasticDisk
                }
                if(ea.InstancePoolID != nil) {
                objectMap["instance_pool_id"] = ea.InstancePoolID
                }
                return json.Marshal(objectMap)
        }

            // Error ...
            type Error struct {
            // ErrorCode - Possible values include: 'ErrorCodeBADREQUEST', 'ErrorCodeCOULDNOTACQUIRELOCK', 'ErrorCodeCUSTOMERUNAUTHORIZED', 'ErrorCodeDIRECTORYNOTEMPTY', 'ErrorCodeDIRECTORYPROTECTED', 'ErrorCodeDRYRUNFAILED', 'ErrorCodeENDPOINTNOTFOUND', 'ErrorCodeFEATUREDISABLED', 'ErrorCodeINTERNALERROR', 'ErrorCodeINVALIDPARAMETERVALUE', 'ErrorCodeINVALIDSTATE', 'ErrorCodeINVALIDSTATETRANSITION', 'ErrorCodeIOERROR', 'ErrorCodeMALFORMEDREQUEST', 'ErrorCodeMAXBLOCKSIZEEXCEEDED', 'ErrorCodeMAXNOTEBOOKSIZEEXCEEDED', 'ErrorCodeMAXREADSIZEEXCEEDED', 'ErrorCodePERMISSIONDENIED', 'ErrorCodeQUOTAEXCEEDED', 'ErrorCodeREQUESTLIMITEXCEEDED', 'ErrorCodeRESOURCEALREADYEXISTS', 'ErrorCodeRESOURCEDOESNOTEXIST', 'ErrorCodeRESOURCELIMITEXCEEDED', 'ErrorCodeTEMPORARILYUNAVAILABLE'
            ErrorCode ErrorCode `json:"error_code,omitempty"`
            Message *string `json:"message,omitempty"`
            }

            // Info ...
            type Info struct {
            autorest.Response `json:"-"`
            NumWorkers *int32 `json:"num_workers,omitempty"`
            Autoscale *AutoScale `json:"autoscale,omitempty"`
            ClusterID *string `json:"cluster_id,omitempty"`
            CreatorUserName *string `json:"creator_user_name,omitempty"`
            Driver *SparkNode `json:"driver,omitempty"`
            Executors *[]SparkNode `json:"executors,omitempty"`
            SparkContextID *int64 `json:"spark_context_id,omitempty"`
            JdbcPort *int32 `json:"jdbc_port,omitempty"`
            ClusterName *string `json:"cluster_name,omitempty"`
            SparkVersion *string `json:"spark_version,omitempty"`
            SparkConf map[string]*string `json:"spark_conf"`
            AwsAttributes *AwsAttributes `json:"aws_attributes,omitempty"`
            NodeTypeID *string `json:"node_type_id,omitempty"`
            DriverNodeTypeID *string `json:"driver_node_type_id,omitempty"`
            SSHPublicKeys *[]string `json:"ssh_public_keys,omitempty"`
            CustomTags map[string]*string `json:"custom_tags"`
            ClusterLogConf *LogConf `json:"cluster_log_conf,omitempty"`
            InitScripts *[]InitScriptInfo `json:"init_scripts,omitempty"`
            DockerImage *DockerImage `json:"docker_image,omitempty"`
            SparkEnvVars map[string]*string `json:"spark_env_vars"`
            AutoterminationMinutes *int32 `json:"autotermination_minutes,omitempty"`
            EnableElasticDisk *bool `json:"enable_elastic_disk,omitempty"`
            InstancePoolID *string `json:"instance_pool_id,omitempty"`
            // ClusterSource - Possible values include: 'UI', 'JOB', 'API'
            ClusterSource Source `json:"cluster_source,omitempty"`
            // State - Possible values include: 'PENDING', 'RUNNING', 'RESTARTING', 'RESIZING', 'TERMINATING', 'TERMINATED', 'ERROR', 'UNKNOWN'
            State State `json:"state,omitempty"`
            StateMessage *string `json:"state_message,omitempty"`
            StartTime *int64 `json:"start_time,omitempty"`
            TerminatedTime *int64 `json:"terminated_time,omitempty"`
            LastStateLossTime *int64 `json:"last_state_loss_time,omitempty"`
            LastActivityTime *int64 `json:"last_activity_time,omitempty"`
            ClusterMemoryMb *int64 `json:"cluster_memory_mb,omitempty"`
            ClusterCores *float64 `json:"cluster_cores,omitempty"`
            DefaultTags map[string]*string `json:"default_tags"`
            ClusterLogStatus *LogSyncStatus `json:"cluster_log_status,omitempty"`
            TerminationReason *TerminationReason `json:"termination_reason,omitempty"`
            }

        // MarshalJSON is the custom marshaler for Info.
        func (i Info)MarshalJSON() ([]byte, error){
        objectMap := make(map[string]interface{})
                if(i.NumWorkers != nil) {
                objectMap["num_workers"] = i.NumWorkers
                }
                if(i.Autoscale != nil) {
                objectMap["autoscale"] = i.Autoscale
                }
                if(i.ClusterID != nil) {
                objectMap["cluster_id"] = i.ClusterID
                }
                if(i.CreatorUserName != nil) {
                objectMap["creator_user_name"] = i.CreatorUserName
                }
                if(i.Driver != nil) {
                objectMap["driver"] = i.Driver
                }
                if(i.Executors != nil) {
                objectMap["executors"] = i.Executors
                }
                if(i.SparkContextID != nil) {
                objectMap["spark_context_id"] = i.SparkContextID
                }
                if(i.JdbcPort != nil) {
                objectMap["jdbc_port"] = i.JdbcPort
                }
                if(i.ClusterName != nil) {
                objectMap["cluster_name"] = i.ClusterName
                }
                if(i.SparkVersion != nil) {
                objectMap["spark_version"] = i.SparkVersion
                }
                if(i.SparkConf != nil) {
                objectMap["spark_conf"] = i.SparkConf
                }
                if(i.AwsAttributes != nil) {
                objectMap["aws_attributes"] = i.AwsAttributes
                }
                if(i.NodeTypeID != nil) {
                objectMap["node_type_id"] = i.NodeTypeID
                }
                if(i.DriverNodeTypeID != nil) {
                objectMap["driver_node_type_id"] = i.DriverNodeTypeID
                }
                if(i.SSHPublicKeys != nil) {
                objectMap["ssh_public_keys"] = i.SSHPublicKeys
                }
                if(i.CustomTags != nil) {
                objectMap["custom_tags"] = i.CustomTags
                }
                if(i.ClusterLogConf != nil) {
                objectMap["cluster_log_conf"] = i.ClusterLogConf
                }
                if(i.InitScripts != nil) {
                objectMap["init_scripts"] = i.InitScripts
                }
                if(i.DockerImage != nil) {
                objectMap["docker_image"] = i.DockerImage
                }
                if(i.SparkEnvVars != nil) {
                objectMap["spark_env_vars"] = i.SparkEnvVars
                }
                if(i.AutoterminationMinutes != nil) {
                objectMap["autotermination_minutes"] = i.AutoterminationMinutes
                }
                if(i.EnableElasticDisk != nil) {
                objectMap["enable_elastic_disk"] = i.EnableElasticDisk
                }
                if(i.InstancePoolID != nil) {
                objectMap["instance_pool_id"] = i.InstancePoolID
                }
                if(i.ClusterSource != "") {
                objectMap["cluster_source"] = i.ClusterSource
                }
                if(i.State != "") {
                objectMap["state"] = i.State
                }
                if(i.StateMessage != nil) {
                objectMap["state_message"] = i.StateMessage
                }
                if(i.StartTime != nil) {
                objectMap["start_time"] = i.StartTime
                }
                if(i.TerminatedTime != nil) {
                objectMap["terminated_time"] = i.TerminatedTime
                }
                if(i.LastStateLossTime != nil) {
                objectMap["last_state_loss_time"] = i.LastStateLossTime
                }
                if(i.LastActivityTime != nil) {
                objectMap["last_activity_time"] = i.LastActivityTime
                }
                if(i.ClusterMemoryMb != nil) {
                objectMap["cluster_memory_mb"] = i.ClusterMemoryMb
                }
                if(i.ClusterCores != nil) {
                objectMap["cluster_cores"] = i.ClusterCores
                }
                if(i.DefaultTags != nil) {
                objectMap["default_tags"] = i.DefaultTags
                }
                if(i.ClusterLogStatus != nil) {
                objectMap["cluster_log_status"] = i.ClusterLogStatus
                }
                if(i.TerminationReason != nil) {
                objectMap["termination_reason"] = i.TerminationReason
                }
                return json.Marshal(objectMap)
        }

            // InitScriptInfo ...
            type InitScriptInfo struct {
            Dbfs *DbfsStorageInfo `json:"dbfs,omitempty"`
            S3 *S3StorageInfo `json:"s3,omitempty"`
            }

            // ListInfo ...
            type ListInfo struct {
            autorest.Response `json:"-"`
            Value *[]Info `json:"value,omitempty"`
            }

            // ListNodeType ...
            type ListNodeType struct {
            autorest.Response `json:"-"`
            Value *[]NodeType `json:"value,omitempty"`
            }

            // LogConf ...
            type LogConf struct {
            Dbfs *DbfsStorageInfo `json:"dbfs,omitempty"`
            S3 *S3StorageInfo `json:"s3,omitempty"`
            }

            // LogSyncStatus ...
            type LogSyncStatus struct {
            LastAttempted *int64 `json:"last_attempted,omitempty"`
            LastException *string `json:"last_exception,omitempty"`
            }

            // NodeType ...
            type NodeType struct {
            NodeTypeID *string `json:"node_type_id,omitempty"`
            MemoryMb *int32 `json:"memory_mb,omitempty"`
            NumCores *float64 `json:"num_cores,omitempty"`
            Description *string `json:"description,omitempty"`
            InstanceTypeID *string `json:"instance_type_id,omitempty"`
            IsDeprecated *bool `json:"is_deprecated,omitempty"`
            NodeInfo *CloudProviderNodeInfo `json:"node_info,omitempty"`
            }

            // ParameterPair ...
            type ParameterPair struct {
            Username *string `json:"username,omitempty"`
            AwsAPIErrorCode *string `json:"aws_api_error_code,omitempty"`
            AwsInstanceStateReason *string `json:"aws_instance_state_reason,omitempty"`
            AwsSpotRequestStatus *string `json:"aws_spot_request_status,omitempty"`
            AwsSpotRequestFaultCode *string `json:"aws_spot_request_fault_code,omitempty"`
            AwsImpairedStatusDetails *string `json:"aws_impaired_status_details,omitempty"`
            AwsInstanceStatusEvent *string `json:"aws_instance_status_event,omitempty"`
            AwsErrorMessage *string `json:"aws_error_message,omitempty"`
            DatabricksErrorMessage *string `json:"databricks_error_message,omitempty"`
            InactivityDurationMin *string `json:"inactivity_duration_min,omitempty"`
            InstanceID *string `json:"instance_id,omitempty"`
            InstancePoolID *string `json:"instance_pool_id,omitempty"`
            InstancePoolErrorCode *string `json:"instance_pool_error_code,omitempty"`
            }

            // PermanentDeleteAttributes ...
            type PermanentDeleteAttributes struct {
            ClusterID *string `json:"cluster_id,omitempty"`
            }

            // ResizeAttributes ...
            type ResizeAttributes struct {
            NumWorkers *int32 `json:"num_workers,omitempty"`
            Autoscale *AutoScale `json:"autoscale,omitempty"`
            ClusterID *string `json:"cluster_id,omitempty"`
            }

            // RestartAttributes ...
            type RestartAttributes struct {
            ClusterID *string `json:"cluster_id,omitempty"`
            }

            // S3StorageInfo ...
            type S3StorageInfo struct {
            Destination *string `json:"destination,omitempty"`
            Region *string `json:"region,omitempty"`
            Endpoint *string `json:"endpoint,omitempty"`
            EnableEncryption *bool `json:"enable_encryption,omitempty"`
            EncryptionType *string `json:"encryption_type,omitempty"`
            KmsKey *string `json:"kms_key,omitempty"`
            CannedACL *string `json:"canned_acl,omitempty"`
            }

            // SparkNode ...
            type SparkNode struct {
            PrivateIP *string `json:"private_ip,omitempty"`
            PublicDNS *string `json:"public_dns,omitempty"`
            NodeID *string `json:"node_id,omitempty"`
            InstanceID *string `json:"instance_id,omitempty"`
            StartTimestamp *int64 `json:"start_timestamp,omitempty"`
            NodeAwsAttributes *SparkNodeAwsAttributes `json:"node_aws_attributes,omitempty"`
            HostPrivateIP *string `json:"host_private_ip,omitempty"`
            }

            // SparkNodeAwsAttributes ...
            type SparkNodeAwsAttributes struct {
            IsSpot *bool `json:"is_spot,omitempty"`
            }

            // TerminationReason ...
            type TerminationReason struct {
            // Code - Possible values include: 'USERREQUEST', 'JOBFINISHED', 'INACTIVITY', 'CLOUDPROVIDERSHUTDOWN', 'COMMUNICATIONLOST', 'CLOUDPROVIDERLAUNCHFAILURE', 'SPARKSTARTUPFAILURE', 'INVALIDARGUMENT', 'UNEXPECTEDLAUNCHFAILURE', 'INTERNALERROR', 'SPARKERROR', 'METASTORECOMPONENTUNHEALTHY', 'DBFSCOMPONENTUNHEALTHY', 'DRIVERUNREACHABLE', 'DRIVERUNRESPONSIVE', 'INSTANCEUNREACHABLE', 'CONTAINERLAUNCHFAILURE', 'INSTANCEPOOLCLUSTERFAILURE', 'REQUESTREJECTED', 'INITSCRIPTFAILURE', 'TRIALEXPIRED'
            Code Code `json:"code,omitempty"`
            Parameters *ParameterPair `json:"parameters,omitempty"`
            }

